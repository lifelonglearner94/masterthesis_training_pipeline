# @package _global_
# =============================================================================
# Continual Learning Pipeline — AC-HOPE-ViT (Param-Matched)
# =============================================================================
# Full CL experiment: Base Training (5000 clips) → 5 Sequential Tasks (finetune)
# with full evaluation after each phase.
#
# Usage:
#   uv run src/cl_train.py experiment=cl_ac_hope paths.data_dir=/path/to/clips
#
# Architecture: AC-HOPE-ViT param-matched (depth=6, ~42M params)
#   - Self-Modifying Titan memories + CMS multi-frequency MLPs
#   - Inner-loop DGD runs during both training and inference
#
# Task training: Regular fine-tuning (gradient descent on task clips)
# Evaluation: Frozen model + frozen inner-loop DGD → pure retrieval, no updates
#
# W&B: Each phase creates a new run, all grouped under cl.wandb_group
# =============================================================================

defaults:
  - override /data: precomputed_features
  - override /model: ac_hope_vit
  - override /trainer: default
  - override /callbacks: default
  - override /logger: wandb

# =============================================================================
# EXPERIMENT METADATA
# =============================================================================
task_name: "cl_ac_hope"
tags: ["cl", "continual_learning", "ac_hope", "titan", "cms", "param_matched"]
seed: 42
train: True
test: False

# =============================================================================
# DATA DEFAULTS (overridden per phase by cl_train.py)
# =============================================================================
data:
  batch_size: 16
  num_workers: 4
  pin_memory: true

# =============================================================================
# MODEL: AC-HOPE-ViT Param-Matched (same as ac_hope_vit_param_matched.yaml)
# =============================================================================
model:
  T_teacher: 7
  jump_k: 3
  use_activation_checkpointing: false  # HOPE DGD incompatible with checkpointing
  action_embed_dim: 2

  # HOPE architecture (param-matched: depth=6, ~42M params)
  depth: 6
  titan_hidden_multiplier: 2
  use_rope: true
  titan_grad_clip_inner: 1.0
  chunk_size: 1
  titan_detach_interval: 1
  surprise_threshold: 0.0

  # CMS levels
  cms_level_specs:
    - name: "fast"
      update_period: 1
      hidden_multiplier: 4.0
      warmup_steps: 0
    - name: "medium"
      update_period: 4
      hidden_multiplier: 4.0
      warmup_steps: 0
    - name: "slow"
      update_period: 16
      hidden_multiplier: 4.0
      warmup_steps: 0

  # Diagnostics
  log_hope_diagnostics: true

  # Loss
  loss_weight_teacher: 1.0
  loss_weight_jump: 1.0
  loss_type: "l1"

  # Curriculum for base training  ... did set it to 1.0, so effectively no curriculum
  curriculum_schedule:
    - epoch: 0
      loss_weight_teacher: 1.0
    - epoch: 15
      loss_weight_teacher: 1.0
    - epoch: 25
      loss_weight_teacher: 1.0

  # Optimizer (HOPE bi-level optimization)
  learning_rate: 1.5e-4
  weight_decay: 0.04
  betas: [0.9, 0.999]

  # Per-group LR scaling
  titan_lr_scale: 0.2
  cms_lr_scale: 1.0
  titan_weight_decay: 0.005
  aux_loss_weight: 0.1

  # LR schedule (longer warmup for meta-learning)
  use_iteration_scheduler: true
  warmup_pct: 0.15
  constant_pct: 0.75
  decay_pct: 0.10
  warmup_start_lr: 3.0e-5

  # TTA defaults (not used for task training, but available)
  tta_enabled: false

# =============================================================================
# TRAINER DEFAULTS (overridden per phase by cl_train.py)
# =============================================================================
trainer:
  max_epochs: 40
  precision: 32  # HOPE inner-loop needs full precision
  gradient_clip_val: 3.0
  gradient_clip_algorithm: norm

# =============================================================================
# CONTINUAL LEARNING PIPELINE CONFIGURATION
# =============================================================================
cl:
  # W&B grouping
  wandb_group: "cl_ac_hope_${now:%Y%m%d_%H%M%S}"

  # Task training mode: "finetune" for HOPE (regular gradient descent)
  task_training_mode: "finetune"

  # Resume: set to a checkpoint path to skip base training and start from tasks
  # e.g.  cl.resume_from_base_checkpoint=/path/to/base_training_final.ckpt
  resume_from_base_checkpoint: null

  # --- Base Training Phase ---
  base_training:
    clip_start: 0
    clip_end: 5000
    max_epochs: 40
    val_split: 0.1

  # --- Sequential Tasks ---
  tasks:
    - name: "scaling_shift"
      clip_start: 5000
      clip_end: 6000
    - name: "dissipation_shift"
      clip_start: 6000
      clip_end: 7000
    - name: "discretization_shift"
      clip_start: 7000
      clip_end: 8000
    - name: "kinematics_shift"
      clip_start: 8000
      clip_end: 9000
    - name: "compositional_ood"
      clip_start: 9000
      clip_end: 10000

  # --- Evaluation Configuration ---
  eval:
    clips_per_task: 100

  # --- Task Training Settings (fine-tuning) ---
  task_training:
    max_epochs: 10
    val_split: 0.0
    # Lower LR for fine-tuning to reduce catastrophic forgetting (1/3 of base LR)
    learning_rate: 5e-5
