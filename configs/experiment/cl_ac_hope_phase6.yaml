# @package _global_
# =============================================================================
# Continual Learning Pipeline — AC-HOPE-ViT Phase 6: Cross-Clip Longterm Memory
# =============================================================================
# Builds on Phase 5 (temporal embeddings + spatial mixing) and adds:
#
#   3. PERSISTENT LONGTERM MEMORY (Ansatz B — Separation of Concerns)
#
#      Problem: All Titan memories are reset between clips. The model has NO
#      mechanism to accumulate knowledge across clips — only standard backprop
#      updates nn.Parameters, which is just SGD with extra steps.
#
#      This is like a brain without long-term memory: it can adapt within a
#      single experience (clip) but forgets everything before the next one.
#
#      Solution: Add M_longterm — a 6th Titan memory that is NEVER reset
#      between clips. This creates a separation of concerns:
#
#        M_memory (clip-level):
#          - Reset every clip (fresh start from nn.Parameters)
#          - Fast DGD adaptation to current physics/task
#          - FREE to specialize on current distribution
#
#        M_longterm (persistent):
#          - Survives across all clips and tasks
#          - Slow DGD accumulation (η × 0.1 of clip-level rate)
#          - Learns the COMMON physics kernel across all experiences
#
#      A learned per-token gate decides when to use clip vs. longterm memory:
#        output = gate * M_memory(q) + (1 - gate) * M_longterm(q)
#
#      Analogy: M_memory = hippocampus (fast, episodic)
#               M_longterm = neocortex (slow, consolidated)
#
#      Why this helps BOTH plasticity AND forgetting:
#        - Plasticity ↓: M_memory starts clean each clip, no old-task inertia
#        - Forgetting ↓: M_longterm preserves common patterns across tasks
#
# Architecture: depth=5, titan_mult=4, CMS={2.0/2.5/3.0}, spatial_mixing=true,
#               longterm_memory=true (mult=2)
# Param budget: ~46.5M (43.5M base + 3M longterm, vs 43M ViT baseline)
#               The +3M is from M_longterm — a persistent buffer mechanism that
#               has no standard ViT equivalent, so direct param matching is N/A.
#
# Usage:
#   uv run src/cl_train.py experiment=cl_ac_hope_phase6 paths.data_dir=/path/to/clips
# =============================================================================

defaults:
  - override /data: precomputed_features
  - override /model: ac_hope_vit
  - override /trainer: default
  - override /callbacks: default
  - override /logger: wandb

# =============================================================================
# EXPERIMENT METADATA
# =============================================================================
task_name: "cl_ac_hope_phase6"
tags: ["cl", "continual_learning", "ac_hope", "titan", "cms", "phase6",
       "longterm_memory", "spatial_mixing", "temporal_embed"]
seed: 42
train: True
test: False

# =============================================================================
# DATA DEFAULTS (overridden per phase by cl_train.py)
# =============================================================================
data:
  batch_size: 16
  num_workers: 4
  pin_memory: true

# =============================================================================
# MODEL: AC-HOPE-ViT Phase 6 (depth=5, ~46.5M params)
# =============================================================================
model:
  T_teacher: 7
  jump_k: 3
  use_activation_checkpointing: false  # HOPE DGD incompatible with checkpointing
  action_embed_dim: 2

  # HOPE architecture — depth=5, titan_mult=4, heterogeneous CMS
  depth: 5
  titan_hidden_multiplier: 4
  use_rope: false                 # RoPE disabled: temporal info from learnable embeddings
  titan_grad_clip_inner: 1.0
  chunk_size: 1
  titan_detach_interval: 2
  surprise_threshold: 0.1

  # Spatial mixing (Phase C) — cross-token interaction (from Phase 5)
  use_spatial_mixing: true

  # ─── NEW: Cross-clip persistent longterm memory (Ansatz B) ───
  # M_longterm persists across clips, accumulating slow knowledge via DGD.
  # Learned gate interpolates between clip-level M_memory and persistent M_longterm.
  use_longterm_memory: true
  longterm_hidden_multiplier: 2   # Smaller than M_memory (4) — compact slow summary
  longterm_lr_scale: 0.1          # 10× slower DGD updates than clip-level memories

  # CMS levels — frame-aware scheduling with heterogeneous capacity
  cms_use_chunk_scheduling: true
  cms_level_specs:
    - name: "fast"
      update_period: 1
      hidden_multiplier: 2.0
      warmup_steps: 0
    - name: "medium"
      update_period: 3
      hidden_multiplier: 2.5
      warmup_steps: 0
    - name: "slow"
      update_period: 7
      hidden_multiplier: 3.0
      warmup_steps: 0

  # Diagnostics
  log_hope_diagnostics: true

  # Loss
  loss_weight_teacher: 1.0
  loss_weight_jump: 1.0
  loss_type: "l1"

  # Curriculum for base training — disabled
  curriculum_schedule:
    - epoch: 0
      loss_weight_teacher: 1.0
    - epoch: 15
      loss_weight_teacher: 1.0
    - epoch: 25
      loss_weight_teacher: 1.0

  # Optimizer — AdamW
  optimizer_type: "adamw"
  learning_rate: 2.5e-4
  weight_decay: 0.04
  betas: [0.9, 0.999]

  # Per-group LR scaling
  titan_lr_scale: 0.3
  cms_lr_scale: 1.0
  titan_weight_decay: 0.005
  aux_loss_weight: 0.1

  # LR schedule
  use_iteration_scheduler: true
  warmup_pct: 0.10
  constant_pct: 0.80
  decay_pct: 0.10
  warmup_start_lr: 5.0e-5

  # TTA defaults
  tta_enabled: false

# =============================================================================
# TRAINER DEFAULTS
# =============================================================================
trainer:
  max_epochs: 65
  precision: 32
  gradient_clip_val: 1.5
  gradient_clip_algorithm: norm
  accumulate_grad_batches: 1

# =============================================================================
# CONTINUAL LEARNING PIPELINE CONFIGURATION
# =============================================================================
cl:
  wandb_group: "cl_ac_hope_phase6_${now:%Y%m%d_%H%M%S}"
  task_training_mode: "finetune"
  resume_from_base_checkpoint: null

  base_training:
    clip_start: 0
    clip_end: 5000
    max_epochs: 65
    val_split: 0.1

  tasks:
    - name: "scaling_shift"
      clip_start: 5000
      clip_end: 6000
    - name: "dissipation_shift"
      clip_start: 6000
      clip_end: 7000
    - name: "discretization_shift"
      clip_start: 7000
      clip_end: 8000
    - name: "kinematics_shift"
      clip_start: 8000
      clip_end: 9000
    - name: "compositional_ood"
      clip_start: 9000
      clip_end: 10000

  eval:
    clips_per_task: 100

  task_training:
    max_epochs: 10
    val_split: 0.0
    learning_rate: 1.5e-4
    warmup_pct: 0.05
    warmup_start_lr: 3.0e-5
